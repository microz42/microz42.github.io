---
layout  : wiki
title   : ch5 - loss function(손실 함수)
summary : 
date    : 2025-06-02 16:10:26 +0900
updated : 2025-06-04 09:48:12 +0900
tag     : loss function
resource: 7F/BC1F34-4BB7-4304-9C62-30FCE4C7DE83
toc     : true
public  : true
parent  : [[/study/understanding_deep_learning]]
latex   : true
---
* TOC
{:toc}



## 손실 함수는 왜 필요한지??
기본적으로 모델을 "훈련"시킨다는 건, 모델이 정답을 잘 맞히도록 파라미터(모델 내부의 숫자들)을 조절하는 과정이다. 이 때, "잘 맞힌다"는 기준을 제시해주는게 바로 **손실 함수**

내가 만든 모델이 예측한 값과 실제 정답이 얼마나 다른지, 그 틀린 정도를 숫자로 알려준다. 당연히 이 숫자가 작을수록 좋은 모델이다. 그래서 train할 때 이 손실 함수의 값을 최소로 만드는 파라미터를 찾는게 목표다.

- 모델을 만들고나면 이 모델이 얼마나 잘 예측하는지, 혹은 얼마나 엉터리인지 평가할 성적표가 필요하다.  
- 그게 바로 손실 함수(loss function) 또는 비용 함수(cost function)

모델이 예측한 값(f[xᵢ, ϕ])과 실제 정답(yᵢ) 사이가 얼마나 다른지 숫자로 알려준다. 그리고 학습의 목표는 이 손실값을 최소로 만드는 모델 파라미터(ϕ)를 찾는 거다.  


## 손실 함수의 핵심은 확률
maximum likelihood라는 걸 통해 손실 함수를 만들 수 있다.

### 단순 출력이 아닌 확률 분포를 예측
원래는 모델이 그냥 '답은 ㅇㅇㅇ'하고 예측값을 내뱉었다면, 여기서는 모델이 특정 입력(x)에 대해 가능한 출력(y)들의 확률 분포 Pr(y∣x)를 예측한다고 본다.
- 예를 들어 날씨 예측:
	- 옛날(?) 모델: 내일 비 올 확률 70% (하나의 값)
	- ch5 모델: 내일 맑을 확률 20%, 흐릴 확률 10%, 비 올 확률 70% (확률 분포)
- 숫자 맞히기 (회귀, Regression) 예시:
	- 입력 x가 2일 때, y가 0.5일 확률, 1.0일 확률, 1.5일 확률.. 이런 식으로 y 값들에 대한 확률을 쫙 알려준다. 모델은 이 확률 분포의 모양(평균, 분산 등)을 결정하는 파라미터를 예측한다.
	- "y는 3 근처일 확률이 높고, 10일 확률은 낮다!!" > y는 이 근처에 있을 것 같다~ 라는 확률분포(곡선)을 예측
	- 아래 5.1a figure 예시 참고

![5.1afigure](https://i.imgur.com/9jZbnfD.png)


### 가장 그럴듯한 파라미터 찾기: maximum likelihood
훈련 데이터셋에는 실제 입력(xi)와 정답 (yi) 쌍이 있는데,  
모델이 예측한 확률 분포 Pr(yi|xi) 하에서, 이 실제 정답 yi들이 나타날 확률이 최대한 높아지도록 모델 파라미터(ϕ)를 조절한다.

모든 훈련 데이터에 대해서 이 확률들을 다 곲한 값(likelihood)을 최대로 만드는 ϕ를 찾는 것. (정확한 건 수식 5.1 참고 pg.58)

### 로그 씌워서 부호 바꾸기
확률은 0에서 1사이의 값이라, 이걸 여러 개 곱하면 숫자가 너무너무 작아져서 다루기 힘들어진다. 

그래서 꼼수를 생각해냈는데,  
log를 씌우자.

log를 씌우면 곱셈이 덧셈으로 바뀐다.


$$
\hat{\phi} = \arg\max_{\phi} \left[ \prod_{i=1}^{I} Pr(y_i \mid f[x_i, \phi]) \right] \\
= \arg\max_{\phi} \log \left[ \prod_{i=1}^{I} Pr(y_i \mid f[x_i, \phi]) \right] \\
= \arg\max_{\phi} \left[ \sum_{i=1}^{I} \log Pr(y_i \mid f[x_i, \phi]) \right]
$$

- 첫 줄: 전체 데이터 정답이 나올 확률의 곱(=likelihood)를 최대화
- 둘째줄: 곱을 로그로 변경해 수치 안정성 확보
- 세번째: 로그 곱 > 합 형태의 log-likelihood

그래서
- 곱 > 로그 > 합
- likelihood > log-likelihood > negative log-likelihood (loss)가 자연스레 이뤄진다
- 확률을 계속 곱하면 너무 작아져서 수치 오차가 생기니까, 로그를 씌워서 합으로 바꾸면 훨씬 안정적이고, 학습도 잘 된다



보통 최적화 문제는 "최소화" 문제로 풀기 때문에
- log-likelihood에 마이너스(-)를 붙여서  
- negative log-likelihood(NLL)를 만들고  
- 이걸 최소화하는 문제로 바꿔버린다.
그렇게 손실 함수 L[ϕ]가 만들어진다.

$$
\hat{\phi} = \arg\min_{\phi} \left[
  - \sum_{i=1}^{I} \log \left( Pr(y_i \mid f[x_i, \phi]) \right)
\right]
= \arg\min_{\phi} \left[ L[\phi] \right]
$$


## 손실 함수 만들기 요약
1. 어떤 확률 분포를 사용해야 하나?
	- 내가 예측하려는 y 값의 종류에 맞는 확률 분포 Pr(y∣θ)를 고른다
	- 예를 들어: y가 실수면 정규분포, y가 0또는 1이면 베르누이 분포
2. 모델에게 뭘 예측시킬까?
	- 모델 f[x,ϕ]가 이 확률 분포의 파라미터 θ를 예측하도록 설정
	- 예: 정규분포의 평균 μ를 예측
3. 손실함수 정의하고 최소화
	- 위에서 말한 NLL를 손실 함수로 사용해서,
	- 이 값을 최소로 만드는 모델 파라미터 $$\hat{\phi}$$ 를 찾는다
4. 예측할 땐?
	- 훈련된 모델로 새로운 데이터 $$x$$에 대한 확률 분포 $$Pr(y \mid f[x, \hat{\phi}])$$ 를 얻거나, 이 분포에서 가장 확률 높은 값 $$\hat{y}$$를 최종 예측값으로 사용한다.

### 대표 손실 함수

| 유형                                                     | 설명                                                                    | 선택 확률 분포              | 손실 함수                                   |
|----------------------------------------------------------|-------------------------------------------------------------------------|-----------------------------|---------------------------------------------|
| 회귀(주가, 온도)                                         |                                                                         | 정규 분포(normal)           | Least Squares Loss                          |
| 이진 분류(스팸, 고양이냐 개냐)                           |                                                                         | 베르누이 분포(bernoulli)    | Binary Cross-entropy loss                   |
| 다중 클래스 분류(손글씨 숫자, 이미지 종류)               | 모델의 K개 출력을 소프트맥스 함수 통과시켜 각 클래스에 대한 확률로 변환 | 카테고리 (categorical)      | multiclass cross-entorpy loss               |
| multiple outputs(한 번에 여러 값 예측, 물체 종류와 위치) |                                                                         | 각 예측이 독립적이라고 가정 | 각 예측에 대한 손실 함수를 따로 구해서 더함 |


정리,  
이전까지는 모델이 그냥 값을 예측한다고 생각했다면  
5장에서는 모델이 출력 값에 대한 확률 분포의 파라미터를 예측한다고 관점을 바꿨다.
